#import "./template.typ":report
#import "@preview/codelst:2.0.2": sourcecode, sourcefile, codelst
#import "@preview/showybox:2.0.3": showybox

#show: report.with(
  title: "Συστήματα Παράλληλης Επεξεργασίας",
  subtitle: "Εργαστηριακή Αναφορά",
  authors: ("Λάζου Μαρία-Αργυρώ (el20129)",
            "Σπηλιώτης Αθανάσιος (el20175)"),
  team : "parlab09",
  semester: "9ο Εξάμηνο, 2024-2025",
)

#let my_sourcefile(file, lang: auto, ..args) = {
  showybox(
    frame: (
      body-color: rgb(245, 245, 245), // Light background (like VSCode light theme)
      border-color: rgb(200, 200, 200), // Light gray border
      title-color: rgb(200, 200, 200), // Darker gray title for contrast
      radius: 5pt, // Rounded corners
      thickness: 1pt, // Thin border for a clean look
    ),
    breakable: true,
    width: 100%, // Fill the available width
    align: center,
    color: rgb(80, 80, 80), // Dark gray text (like VSCode)
    title: grid(
      columns: (1fr, 1fr), // Two equal-width columns for title and language
      gutter: 1em, // Space between columns
      text(
        font: "DejaVu Sans Mono", // Monospaced font for code
        size: 0.75em,
        fill: rgb(80, 80, 80), // Dark gray title text
        weight: 600,
        file.split("/").at(-1)
      )
    ),
  )[
    #set text(size: 0.85em, font: "DejaVu Sans Mono", fill: rgb(10, 10, 10)) // Black text for the code
    #sourcefile(read(file), file: file, lang: lang, ..args, frame: none)
  ]
}

#let bash_box(file, lang: auto, ..args) = {
  show table.cell.where(y: 0): set text(weight: "regular")

  showybox(
    frame: (
      body-color: rgb("#111"),
      thickness: 0.6pt,
    ),
    breakable: false,
    width: 100%,
    align: center,
  )[
    #set text(
      font: "DejaVu Sans Mono",
      size: 0.8em,
      fill: lime, // Green text color for terminal style
    )
    #sourcefile(
      read(file),
      file: file,
      // lang: "bash",
      ..args,
      frame: none,
      numbering: none,
    )
  ]
}

#let bordered_text(file) = {
  // Read the file content
  let file_content = read(file)
  
  // Display the file content inside the box
  showybox(
    frame: (
      border-color: black,         
      border-thickness: 1pt,       
      radius: 4pt,                 
      thickness: 1pt,             
    ),
    breakable: true,
    width: 100%,                  
    align: center,
 
    text(size: 12pt, fill: black)[#file_content]  
    )
}

/****************************
* Document body, start here.*
*****************************/

= Conway's GameofLife
\
 === Υλοποίηση
Για την παραλληλοποίηση του αλγορίθμου τροποποίησαμε τον κώδικα που δίνεται προσθέτοντας απλώς το \#pragma directive στο κύριο loop για τα (i,j) του body: 

#my_sourcefile("../a1/Game_Of_Life.c",
highlighted: (63,),
  highlight-color:  rgb(85, 0, 170).lighten(60%),) 
\

Για την μεταγλώτιση και εκτέλεση στον scirouter χρησιμοποίησαμε το ακόλουθα scripts :

#bash_box("../a1/make_on_queue.sh")
#bash_box("../a1/omp_run_on_queue.sh")
\
=== Aποτελέσματα Μετρήσεων:
\
#bordered_text("../a1/omp_gameoflife_all.out")
\

=== Γραφική Απεικόνιση και Παρατηρήσεις

#image("../a1/grid64.svg")
Παρατηρούμε ότι για μικρό μέγεθος grid (με συνολική απαίτηση μνήμης 4*64*64bytes =
16KB), δεν υπάρχει ομοιόμορφη κλιμάκωση της επίδοσης με αύξηση των νημάτων από 4
και πάνω. Bottleneck κόστους θα θεωρήσουμε την ανάγκη συγχρονισμού των threads και
το overhead της δημιουργίας τους συγκριτικά με τον φόρτο εργασίας που τους ανατίθεται
(granularity).
\
\
\
#image("../a1/grid1024.svg")
Για μέγεθος grid με συνολική απαίτηση μνήμης 4*1024*1024 bytes = 4ΜB, η επίδοση
βελτίωνεται ομοιόμορφα και ανάλογα με το μέγεθος των νημάτων . Εικάζουμε, λοιπόν, πως
η cache χωράει ολόκληρο το grid ώστε το κάθε νήμα δεν επιβαρύνει την μνήμη με loads
των αντίστοιχων rows, o φόρτος εργασίας είναι ισομοιρασμένος στους workers και το
κόστος επικοινωνίας αμελητέο. Συνεπώς, προκύπτει perfect scaling.

#pagebreak() 

#image("../a1/grid4096.svg")
Για μεγάλο grid (με συνολική απαίτηση μνήμης 4*4096*4096 bytes = 64ΜΒ), η κλιμάκωση
παύει να υφίσταται για περισσότερα από 4 νήματα. Bottleneck κόστους εδώ θεωρούμε το
memory bandwidth. Επειδή ολόκληρο το grid δεν χωράει στην cache, δημιουργούνται
misses όταν ξεχωριστά νήματα προσπαθούν να διαβάσουν ξεχωριστές γραμμές του
previous. Σε κάθε memory request αδειάζουν χρήσιμα data για άλλα νήματα, φέρνοντας τις
δικές τους γραμμές και στο μεταξύ oι υπολογισμοί stall-άρουν.


#pagebreak() 

 === Bonus 

Δύο ενδιαφέρουσες ειδικές αρχικοποιήσεις του ταμπλό είναι το pulse και το gosper glider
gun για τις οποίες η εξέλιξη των γενιών σε μορφή
κινούμενης εικόνας φαίνεται με μορφή gif παρακάτω: 

#align(center)[
#image("../a1/glider_gun.gif", width:75%)
#emph("glider_gun animation")
\
\
#image("../a1/pulse.gif", width: 75%)
#emph("pulse animation")
]

#pagebreak() 

=== Πράρτημα

Για την εξαγωγή των γραφικών παραστάσεων χρησιμοποιήθηκε ο κώδικας σε Python που ακολουθεί:

#my_sourcefile("../a1/plots.py")

#pagebreak() 

= KMEANS
\
== 1) Shared Clusters
=== Υλοποίηση
Για την παραλληλοποίηση της συγκεκριμένης έκδοσης χρησιμοπιήσαμε το parallel for directive του οmp και για την αποφυγή race conditions τα omp atomic directives. Αυτά εμφανίζονται όταν περισσότερα από 1 νήματα προσπαθούν να ανανεώσουν τιμές στους shared πίνακες newClusters και newClusterSize σε indexes τα οποία δεν είναι μοναδικά για το καθένα καθώς και στην shared μεταβλητή delta. Για αυτήν προσφέρεται η χρήση reduction και εδώ μπορεί να αγνοηθεί εντελώς αφού η σύγκλιση του αλγορίθμου καθορίζεται από των πολύ μικρό αριθμό των επαναλήψεων(10). Ωστόσο, χρησιμοποιούμε atomic για ορθότητα της τιμής του και για παρατήρηση με βάση το μεγαλύτερο δυνατό overhead.

#my_sourcefile("../a2/kmeans/omp_naive_kmeans.c",
highlighted: (89,96,106,112),
  highlight-color:  rgb(85, 0, 170).lighten(60%),) 
\
Απεικονίζουμε παρακάτω τα αποτελέσματα των δοκιμών στον sandman για τις διάφορες τιμές της environmental variable OMP_NUM_THREADS:
\
#image("../a2/kmeans/results/fig0.png")

Παρατηρούμε πως ο αλγόριθμος δεν κλιμακώνει καθόλου καλά από 8 και πάνω νήματα εξαιτείας της σειριποίησης των εγγραφών ολοένα και περισσότερων νημάτων που επιβάλλει η omp atomic, και της αυξανόμενης συμφόρησης στο bus κατά την απόκτηση του lock.

#pagebreak() 

== Εκμετάλλευση του GOMP_CPU_AFFINITY 
\

Με την χρήση του environmental variable GOMP_CPU_AFFINITY και στατικό shceduling κάνουμε pin νήματα σε πυρήνες(εφόσον δεν υπάρχει ανάγκη για περίπλοκη δυναμική δρομολόγηση). Έτσι, δεν σπαταλάται καθόλου χρόνος σε flash πυρήνων και αχρείαστη μεταφορά δεδομένων από πυρήνα σε άλλον. 
\
Για την υλοποίηση τροποποίησαμε κατάλληλα το script υποβολής στον sandman και προσθέσαμε την παράμετρο *schedule (static)* στο parallel for. 

\
=== Aποτελέσματα
#image("../a2/kmeans/results/fig1.png")

Παρατηρούμε σημαντική βελτίωση στην κλιμάκωση μέχρι 8 νήματα όμως μετά σταματάει να κλιμακώνει ο αλγόριθμος λόγω της δομής που έχει ο sandman. Για 16 νήματα και πάνω δεν μπορούμε να τα κάνουμε pin στο ίδιο cluster οπότε δεν μοιράζονται τα νήματα την ίδια L3 cache και υπάρχει συνεχής μεταφορά δεδομένων των shared πινάκων και bus invalidations λόγω του cache coherence protocol. Aκόμη τα L3 misses κοστίζουν ξεχωριστά για κάθε cluster. Εαν αξιοποιήσουμε τo hyperthreading και κάνουμε pin τα threads 9-16 στους cores 32-40 που πέφτουν μέσα στο cluster 1 μπορούμε να μειώσουμε σημαντικά τον χρόνο για τα 16 νήματα. Από εκεί και πέρα η κλιμάκωση σταματάει. Παραθέτουμε το τελικό script υποβολής ακολούθως:
\
#bash_box("../a2/kmeans/run_with_gomp.sh")
\
=== Aποτελέσματα
#image("../a2/kmeans/results/fig7.png")

#pagebreak() 

== 2) Copied Clusters & Reduce

=== Yλοποίηση
Μοιράζουμε σε κάθε νήμα ένα διαφορετικό τμήμα των πινάκων newClusters, newClusterSize οπότε τα δεδομένα γίνονται private, δεν υπάρχουν race conditions αλλά απαιτείται reduction (με πρόσθεση) στο τέλος για το τελικό αποτέλεσμα (η οποία πραγματοποιείται εδώ από 1 νήμα). 

// TODO add code here !
#my_sourcefile("../a2/kmeans/omp_reduction_kmeans1.c",
highlighted: (76,77,85,86,87,88,89,106,107,108,109,110,111,112,113,115,117,120,138,139,140,149,150,151,152,153,154,155),
   highlight-color:  rgb(85, 0, 170).lighten(60%),) 

=== Aποτελέσματα
#image("../a2/kmeans/results/fig2.png")

Παρατηρούμε τέλεια κλιμάκωση μέχρι και τα 32 νήματα και αρκετά καλή και στα 64 εφόσον δεν εισάγουμε overheads συγχρονισμού και η σειριακή ενοποίηση (reduction) δεν είναι computational intensive για να καθυστρεί τον αλγόριθμο. 
\
\
=== Δοκιμές με μικρότερο dataset

Τα αποτελέσματα δεν είναι ίδια για άλλα μεγέθη πινάκων. Συγκεκριμένα για το επόμενο configuration παρατηρούμε τα εξής:

 #image("../a2/kmeans/results/fig3.png") 

Κυρίαρχo ρόλο για αυτήν την συμπεριφορά αποτελεί το φαινόμενο false sharing, που εμφανίζεται σε μικρά datasets (εδώ κάθε object έχει μόνο 1 συντεταγμένη!) όταν σε ένα cache line καταφέρνουν να χωρέσουν παραπάνω από 1 objects και σε κάθε εγγραφή γίνονται πάρα πολλά περιττά invalidations. Mια λύση είναι το padding όμως έχει memory overhead και δεν προτιμάται.

=== First-touch Policy 
Προς αποφυγή των παραπάνω εκμεταλλευόμαστε την πολιτική των linux κατά το mapping των virtual με physical addresses. H δέσμευση φυσικής μνήμης πραγματοποιείται κατά την 1η εγγραφή του αντικειμένου (η calloc το εξασφαλίζει γράφοντας 0 ενώ η malloc όχι) οπότε εαν το κάθε νήμα γράψει ξεχωριστά στο κομμάτι του πίνακα που του αντιστοιχεί (ουσιαστικά παραλληλοποιώντας την αντιγραφή των shared πινάκων) θα απεικονιστεί στην μνήμη του αυτό και μόνο. 
=== Υλοποίηση 
// TODO add code here !
#my_sourcefile("../a2/kmeans/omp_reduction_kmeans.c",
highlighted: (75,76,99,100,101,102,103,104,105,106,107,108,109,110,111,112),
    highlight-color:  rgb(85, 0, 170).lighten(60%),) 


=== Αποτελέσματα 

#image("../a2/kmeans/results/fig4.png")

Υπάρχει σαφής βελτίωση και καλή κλιμάκωση μέχρι τα 32 νήματα ακόμα και σε σχέση με την ιδανική εκτέλεση του σειριακού αλγορίθμου. Ο καλύτερος χρόνος σε αυτό το ερώτημα είναι 0.4605s στα 32 νήματα! 

=== Numa-aware initialization

Με βάση όσα αναφέρθηκαν για το pinning σε cores και την πολιτική first-touch η αρχικοποίηση των shared πινάκων μπορεί να γίνει και αυτή ατομικά από κάθε νήμα σε ένα private τμήμα αυτού. Για την υλοποίηση προσθέτουμε το omp parallel for directive με στατική δρομολόγηση. Aυτή είναι απαραίτητη ώστε τα νήματα που θα βάλουν τους τυχαίους αριθμούς στα objects να είναι τα ίδια νήματα με αυτά που θα τα επεξεργαστούν στην main.c με σκοπό να είναι ήδη στις caches και να μην χρειάζεται να τα μεταφέρνουν από την κύρια μνήμη ή από άλλα νήματα. 
=== Υλοποίηση 
Τροποποιούμε το file_io.c που δίνεται : 
// TODO add code here !
#my_sourcefile("../a2/kmeans/file_io.c",
highlighted: (28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50),
    highlight-color:  rgb(85, 0, 170).lighten(60%),) 
)



\
=== Αποτελέσματα 

#image("../a2/kmeans/results/fig5.png")

Παρατηρούμε καλύτερη κλιμάκωση μέχρι τα 32 νήματα με χρόνο 0.2667s!
Το κυρίαρχο bottleneck σε αυτήν την περίπτωση είναι το overhead της δημιουργίας των νημάτων.

\
\
Tέλος με όλες τις προηγούμενες αλλαγές δοκιμάζουμε ξανά το μεγάλο dataset που είχαμε στην αρχή:

#image("../a2/kmeans/results/fig6.png")

Παρατηρούμε πως υπάρχει τέλεια κλιμάκωση του αλγορίθμου. Οπότε bottleneck θα μπορούσε να θεωρηθεί το computive intensity για κάθε object.

#pagebreak() 

= FLOYD WARSHALL

== 1) Recursive 

=== Υλοποίηση

\
Δημιουργούμε ένα παράλληλο section κατά την πρώτη κλήση αφού έχουμε ενεργοποιήσει την επιλογή για nested tasks μέσω τηw  omp_set_nested(1). (*Μπορούμε να το θέσουμε και ως environmental variable (OMP_NESTED=TRUE, OMP_MAX_ACTIVE_LEVELS=64) *)
Για την διατήρηση των εξαρτήσεων κατά τον υπολογισμό των blocks (A11) -> (A12 A21) -> A22 και αντιστρόφως τοποθετούμε κατάλληλα barriers έμμεσα με τα taskwait directives. 

#my_sourcefile("../a2/FW/fw_sr.c",
highlighted: (13,43,45,49,50,51,52,53,54,55,95,97,102,104,106),
    highlight-color:  rgb(85, 0, 170).lighten(60%),) 

\
#pagebreak()

Πειραματιστήκαμε σχετικά με την βέλτιστη τιμή του BSIZE τρέχοντας τις προσομοιώσεις που ακολουθούν. Διαισθητικά η optimal τιμή οφείλει να εκμεταλλεύεται πλήρως το cache size και δεδομένου ότι έχουμε τετράγωνο grid για 1 recursive call που δημιουργεί 4 sub-blocks μεγέθους B θα είναι Βopt = sqrt(cache size). Για τα πειράματα χρησιμοποιήσαμε το ακόλουθο script: 
\
#bash_box("../a2/FW/run_on_queue.sh")
\

=== Aποτελέσματα 
\
#align(center)[
===  {N = 1024}
\
#image("../a2/FW/results/fig1024_16.png", width:60%)
#image("../a2/FW/results/fig1024_32.png", width:60%)
#image("../a2/FW/results/fig1024_64.png", width:60%)
#image("../a2/FW/results/fig1024_128.png", width:60%)
#image("../a2/FW/results/fig1024_256.png", width:60%)
\

=== {N = 2048}
\
#image("../a2/FW/results/fig2048_16.png", width:60%)
#image("../a2/FW/results/fig2048_32.png", width:60%)
#image("../a2/FW/results/fig2048_64.png", width:60%)
#image("../a2/FW/results/fig2048_128.png", width:60%)
#image("../a2/FW/results/fig2048_256.png", width:60%)

=== { N = 4096 }
\
#image("../a2/FW/results/fig4096_16.png", width:60%)
#image("../a2/FW/results/fig4096_32.png", width:60%)
#image("../a2/FW/results/fig4096_64.png", width:60%)
#image("../a2/FW/results/fig4096_128.png", width:60%)
#image("../a2/FW/results/fig4096_256.png", width:60%)
]

Kαταλήξαμε πως η ιδανική τιμή είναι Β=64 και ο καλύτερος χρόνος που πετύχαμε χρησιμοποιώντας αυτήν για 4096 μέγεθος πίνακα ήταν 10.4486 με 16 threads. Από το σημείο αυτό και έπειτα ο αλγόριθμος δεν κλιμακώνει και φανερώνει την αδυναμία του χάρη στην αναδρομή.

#pagebreak() 

== 2) TILED

=== Υλοποίηση 

Φτιάχνουμε 1 παράλληλo section με κατάλληλα barriers ώστε να υπολογίζεται πρώτα (single) το k-οστό στοιχείο στην διαγώνιο, έπειτα όσα βρίσκονται κατά μήκος του "σταυρού" που σχηματίζεται εκατέρωθεν αυτού, και τέλος τα blocks στοιχείων που απομένουν. Καθένα από τα στάδια 2 και 3 έχει 4 for loops που μπορούν να παραλληλοποιηθούν με parallel for και επειδή είναι ανεξάρτητα μεταξύ τους με παράμετρο nowait. Το collapse(2) πραγματοποιεί flattening για καλύτερη λειτουργία του parallel for για nested loops. Mε χρήση μόνο των παραπάνω επιτυγχάνουμε χρόνο εκτέλεσης 2.2 secs.  
\
Για περαιτέρω βελτίωση επιχειρήσαμε να χρησιμοποιήσουμε SIMD εντολές αρχικά μέσω του OpenMP με το αντίστοιχο directive και στην συνέχεια γράφοντας χειροκίνητα τις intrinsics εντολές για AVX μοντέλο που υποστηρίζει 4-size vector operations καθώς διαπιστώσαμε ότι vector operations μεγαλύτερου μεγέθους (π.χ με 8 στοιχεία AVX2) δεν υποστηρίζεται στο εν λόγω μηχάνημα και λαμβάνουμε σφάλμα Illegal hardware instruction. Στην πρώτη εκδοχή λάβαμε συνολικό χρόνο εκτέλεσης 1.7secs. 
\
H χρήση των intrisincs απευθείας μας δίνει την δυνατότητα να εκμεταλλευτούμε πλήρως και την αρχιτεκτονική της κρυφής μνήμης μέσω loop unrolling. Συγκεκριμένα, αναγνωρίσαμε ότι το size του cacheline είναι 64bytes, συνεπώς χωράνε 16 integers, ή 4 vectors 4άδων σε όρους AVX. Άρα επιτυγχάνουμε μέγιστο locality exploitation κάνοντας unroll με παράγοντα 4 και αυξάνοντας το j κατά 16 σε κάθε iteration. Ακόμη, παρατηρούμε ότι τα στοιχεία Α[i][k] είναι ανεξάρτητα του j  και η φόρτωση αυτών των vectors μπορεί να γίνει στο εξωτερικό loop. O καλύτερος χρόνος εκτέλεσης που επιτύχαμεμε αυτήν την εκδοχή είναι *1.39 secs!*
\

#my_sourcefile("../a2/FW/fw_smd.c",
highlighted: (4,5,27,28,29,30,40,41,42,43,45,46,50,54,58,62,64,69,74,79,84,94,95,96,97,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153),
    highlight-color:  rgb(85, 0, 170).lighten(60%),) 

=== Aποτελέσματα 

#image("../a2/FW/results/tiled.png")

Παραθέτουμε αναλυτικά και τους βέλτιστους χρόνους:
#bordered_text("../a2/FW/results/smd.out")

#pagebreak() 

== Παράρτημα 
\
Για την δημιουργία των γραφικών παραστάσεων χρημιοποίηθηκαν oι εξής κώδικες σε Python :

#my_sourcefile("../a2/kmeans/results/results.py")
\
\
#my_sourcefile("../a2/FW/results/plots.py")

#pagebreak()

= Αμοιβαίος Αποκλεισμός-Κλειδώματα

\
Στο συγκεκριμένο ερώτημα καλούμαστε να αξιολογήσουμε τους διαφορετικούς τρόπους υλοποίησης κλειδωμάτων για αμοιβαίο αποκλεισμό. 
\
Μας δίνονται έτοιμες όλες οι υλοποίησεις των κλειδωμάτων. Για την εκτέλεση του συγκεκριμένου data set (Size = 32, Coords = 16, Clusters = 32, Loops = 10) στον scirouter χρησιμοποιήσαμε το ακόλουθο script :

#bash_box("../a2_new/kmeans/run_on_queue.sh")

=== Τεχνικές συγχρονισμού

\
1) pthread_mutex_lock
\
Σε αυτήν την τεχνική χρησιμποποιείται ένα κλείδωμα αμοιβαίου αποκλεισμού και μεσολαβεί το λειτουργικό σύστημα σε περίπτωση αποτυχίας (context switch). Έτσι, επιτρέπει σε άλλες διεργασίες να τρέχουν μέχρι να ξυπνήσει από κάποιο κατάλληλο signal. Τότε, επιχειρεί εκ νέου να μπει στο κρίσιμο τμήμα. 
\
\
2) pthread_spin_lock
\
Σε αυτήν την τεχνική, χρησιμποποείται και πάλι ένα κλείδωμα όμως το κάθε νήμα εκτελεί busy waiting loop για την απόκτηση του. Έτσι, δεν επιτρέπει σε άλλο νήμα να τρέξει στην θέση του (εκτός φυσικά εαν περάσει χρόνος ίσος με το runtime quantum και το αποσύρει ο scheduler) σπαταλώντας ωφέλιμο CPU time. Αυτό το μοντέλο προσφέρεται για operations που μπλοκάρουν μόνο για λίγους κύκλους, δηλαδή ο χρόνος αναμονής είναι μικρότερος του context switching overhead.
\
3) tas_lock
\
Αυτή η τεχνική βασίζεται στην υποστήριξη από το υλικό και χρησιμοποιεί την ατομική εντολή test_and_set που προσφέρει το ISA. Θέτει *ταυτόχρονα* το κλείδωμα (μεταβλητή state) σε 1 και επιστρέφει την προηγούμενη τιμή της (μεταβλητή test). Αν η προηγούμενη τιμή είναι 0 τότε το νήμα δέσμευσε επιτυχώς το κλείδωμα. Κάθε νήμα που προσπαθεί να μπει στο κρίσιμο εκτελεί ένα dummy while loop με την tas. Σε κάθε iteration γράφει στην θέση μνήμης της state, που είναι *μοιραζόμενη*, και στέλνει cache line invalidation στα υπόλοιπα με βάση το πρωτόκολλο MESI για συνάφεια κρυφών μνημών. Συνεπώς, δημιουργείται υπερβολικά μεγάλη και περιττή συμφόρηση στο δίαυλο.
\
4) ttas_lock
\
Μοιάζει με την tas, οστόσω το νήμα δεν γράφει απευθείας την state αλλά επιχειρέι πρώτα να την διαβάσει (test). Εαν η τιμή της δεν είναι 0, παραμένει μέσα στο busy wit loop και μόλις διαβάσει τιμή 0, προσπαθεί να γράψει σε αυτήν (test_and_set). Τα διαδοχικά reads δεν κοστίζουν σε bandwidth αφού δεν στέλνουν κάποια ενημέρωση μέσω bus. O αριθμός των writes μειώνεται σημαντικά άρα και τα συνολικά invalidations. Περεταίρω βελτίωση γίνεται με εκθετική οπισθοχώρηση (κατά το read και έτσι μειώνονται dummy CPU cycles και αποφεύγονται περισσότερα αποτυχημένα writes) αλλά δεν το εξετάζουμε σε αυτήν την άσκηση.
\
\
5) array_lock
\
Σε αυτήν την τεχνική κάθε νήμα έχει μια δική του μεταβλητή slot, ένα global πίνακα flag και που είναι τώρα το τέλος της ουράς. Κάθε φορά που προσπαθεί ένα νήμα να πάρει το κλείδωμα, παίρνει το τέλος της ουράς και κάνει ατομική αύξηση κατά 1, θέτει αυτό ως δικό του slot και περιμένει πότε θα γίνει true. Κάθε φορά που ένα νήμα αποδεσμεύει το κλείδωμα, ξαναθέτει το slot του ως false και κάνει το επόμενο true ώστε να πάρει το κλείδωμα αυτός που έχει το επόμενο slot. Αυτή η τεχνική έχει λιγότερη συμφόρηση στο δίαυλο γιατί κάθε νήμα κάνει πάντα 3 αλλαγές για να δεσμεύσει και να αποδεσμεύσει. Επίσης είναι δίκαιη, δηλαδή τα νήματα εκτελούν το κρίσιμο τμήμα με την ίδια σειρά που προσπάθησαν να το δεσμεύσουν. Ωστόσω, ένα νήμα πρέπει να περιμένει στην χειρότερη περίπτωση μια πλήρη περιστροφή του δακτυλίου ώστε να μπει στο κρίσιμο τμήμα ακόμη και αν είναι το μοναδικό που το επιδιώκει.
\
\
6) clh_lock
\
Σε αυτήν την τεχνική κάθε νήμα έχει ένα κόμβο με ένα κλείδωμα. Κάθε φορά που προσπαθεί να δεσμεύσει το κλείδωμα βάζει το δικό του κλείδωμα να είναι 1, αλλάζει ατομικά τον δείκτη στο κόμβο που αναπαριστά το τέλος της ουράς στον εαυτό του και μετά περιμένει πότε το κλείδωμα του προηγούμενου θα γίνει 0. Αντίστοιχα όταν αποδεσμεύει το κλείδωμα απλά θέτει το δικό του κλείδωμα σε 0. Το μεγάλο πλεονέκτημα αυτής της τεχνικής είναι πως είναι πολύ κλιμακώσιμη για αρκετά threads καθώς υπάρχει μόνο 1 κοινή μεταβλητή για τα threads και όχι ολόκληρος πίνακας.
\
\
7) pragma omp critical
\ 
Θα αξιολογήσουμε και την επίδοση της βιβλιοθήκης του OpenMP για το κρίσιμο τμήμα.
\
\
8) pragma omp atomic
\
Θα αξιολογήσουμε επίσης και την επίδοση μέχρι μόνο 2 ατομικών εντολών και όχι κρίσιμου τμήματος, καθώς μπορεί να μην αλλάζουν τις ίδιες μεταβλητές 2 νήματα.

#pagebreak()

=== Aποτελέσματα 

#image("../a2/conc_ll/results/locks_total.png",width:95%)
#image("../a2/conc_ll/results/locks_perloop.png",width:95%)

=== Παρατηρήσεις

Γενικά με την αύξηση των threads τα race conditions είναι συχνότερα οπότε οι συνολικοί χρόνοι εκτέλεσης ανεξαρτήτως μηχανισμού έχουν bottlenecκ το κόστος συγχρονισμού όταν πια η λύση μας πάψει να είναι scalable (από τα 8 threads και πάνω όπως φαίνεται στο σχήμα).

\ *naive* \
H υλοποίηση naive χρησιμοποιεί atomic add για την εγγραφή στα arrays newClusterSize και newClusters. Συγκεκριμένα, για παράμετρο coords = 16, πραγματοποιεί 16 + 1 (για το neeClusterSize) ατομικές εγγραφές. Aπό 8 threads και πάνω, προσεγγίζει καλύτερα από τις υπόλοιπες την no_sync η οποία δεν χρησιμοποιεί κανένα μηχανισμό συγχρονισμού οπότε παράγει λάθος αποτελέσματα) και χρησιμοποιείται μόνο ως σημείο αναφοράς βέλτιστου χρόνου. 

\ *spinlocks* \
Aπό 8 threads και πάνω οι μηχανισμοί #emph("tas") και #emph("ttas") δεν κλιμακώνουν εξαιτείας της συμφόρησης που προκαλούν στον δίαυλο με τα αλλεπάλληλα cache line invalidations ειδικότερα όταν τα δεδομένα χρειάζεται να μεταφέρονται πλέον εκτός του NUMA cluster οπότε χρειάζεται να διατηρείται η συνάφεια και μεταξύ των L3 Caches. 
Aκόμη, όσο περισσότερα γίνονται τα νήματα τόσο αυξάνονται και οι αποτυχημένες προσπάθεις της test_and_set και στις δύο περιπτώσεις εξαιτείας της μεγάλης ζήτηςης του ίδιου locl. Η #emph("ttas") έχει οστόσω καλύτερες επιδόσεις αφού γλιτώνει κάποια περιττά writes, και μάλιστα για < 8 νήματα έχει την καλύτερη επίδοση.
Παρόμοια είναι και η συμπεριφορά του pthread_spinlock αφού όλα βασίζονται στην λογική των busy-wait loops σπαταλώντας CPU time. 
Με βάση το implementation στην glibc, η pthread_spin_lock χρησιμοποιεί ένα υβρίδιο των προηγούμενων 2. Στην 1η προσπάθεια, χρησιμοποιεί την ατομική εντολή atomic_exchange που θεωρεί ταχύτερη εαν παρέχεται από το υλικό και δεν καλεί την CAS (compare_and_swap). Σε περίπτωση αποτυχίας απλά διαβάζει την μεταβλητή όπως η #emph("ttas"). Παραθέτουμε τον αντίστοιχο κώδικα:
#my_sourcefile("../a2/others/pthread_spin_lock.c")

\ *array locks* \
Το array_lock και clh_lock είναι οι πιο scaleable μηχανισμοί αφού δεν χαρακτηρίζονται το overhead της atomic σε < 8 νήματα και από το overhead του προωτοκόλλου MESI για >8 νήματα.
Επειδή τα νήματα εισέρχονται στο κρίσιμο τμήμα με ένα καθορισμένο μοτίβο και όλα εν τέλει θα μπουν σε αυτό, κανένα slot στον δακτύλιο δεν μένει αδρανές, ενώ όσο τα νήματα περιμένουν την σειρά τους δεν πραγματοποιούν ανούσιες προβάσεις την μνήμη. Αντιθέτως, εαν το concurrency rate ήταν μικρότερο, ο μηχανισμός θα έπασχε από το overhead διάσχυσης ολόκληρου του δακτυλίου προκειμένου να ικανοποίησει λ.χ. ένα μόνο αίτημα.
Aντίστοιχα, για το chl_lock μειώνεται το contention για ένα κοινό global lock και κάθε νήμα εκτελεί spinlock στην μεταβλητή του προηγούμενου node. Συγκρούσεις εξακολουθούμε να έχουμε για την είσοδο στο τέλος της ουράς, παρόλα αυτά η διατήρηση μιας λίστας είναι πιο φθηνή από έναν circular buffer και φαίνεται πως γι' αυτό  πετυχείνει καλύετρους χρόνους.

\ *mutex* \
Για < 8 νήματα το context switch είναι αρκετά ακριβό (τουλάχιστον για το συκεκριμένο configuration όπου απαιτεί 17 μόνο πράξεις στο κρίσιμο τμήμα που δεν είναι τόο computational intense), όμως φαίνεται να υπερτερεί έναντι των spinocks για 16 και πάνω νήματα όπου το bus traffic γίνεται αφόρητο. H υλοποίηση του omp critical φαίνεται ότι συδέεται με την χρήση ενός mutex οστόσω έχει χειρότερη επίδοση από το να το καλέσουμε explicitly, που διακιολογούμε εφόσον παρέχει ένα higher level abstraction άρα και επιπλέον overheads. Συγκεκριμένα, διατηρεί μέσω του global context manager ένα mapping για named crirtical regions το οποίο εισάγει μια πολυπλοκότητα, ενώ τα omp directives απαιτούν κάθε φορά και την κλήση της libomp. Παραθέτουμε τον αντίστοιχο κώδικα:
#my_sourcefile("../a2/others/gomp_critical.c")
\
\
Τέλος, όταν έχουμε 1 μόνο νήμα, δεν μπλοκάρει σε καμία απόπειρα απόκτησης του lock γι'αυτό όλες οι υλοποιήσεις είναι καλύτερες από την naive, (tas,ttas,array,clh εκτελούν ακριβώς τις ίδεις εντολές - ανάγονται σε 1 ανάγνωση και 1 εγγραφή) και η mutex υπερτερεί γιατί δεν πραγματοποιεί κανένα context switch.
\
\
*#emph("Σημείωση")* : Αν χρησιμοποιούσαμε hyperthreading για τα 16 νήματα, δηλαδή βάζαμε τα 8 τελευταία νήματα εκτός των 64 λογικών, θα δούμε κλιμάκωση και για 16 νήματα όπως φαίνεται παρακάτω :
#image("../a2_new/kmeans/results/kmeans_results_hyper.png")


#pagebreak()

= Ταυτόχρονες Δομές δεδομένων
\
Σε αυτό το ερώτημα εξετάζουμε πως κλιμακώνουν διάφορες ταυτόχρονες υλοποιήσεις για μια απλά συνδεδεμένη λίστα. 
\
Οι ταυτόχρονες υλοποιήσεις που θα εξετάσουμε είναι οι εξής :
\
\
=== 1) Coarse-grain locking
\
Σε αυτήν την υλοποίηση υπάρχει ένα γενικό κλείδωμα για όλη την δομή. Για κάθε προσθήκη ή αφαίρεση στοιχείου στη λίστα, το νήμα προσπαθεί να δεσμεύσει το κλείδωμα και να κάνει την κατάλληλη αλλαγή. Είναι πολύ απλό στην υλοποίηση όμως δεν θα κλιμακώσει καθόλου καθώς όλοι περιμένουν το ίδιο κλείδωμα και δεν εκμεταλλευόμαστε καθόλου παραλληλία σε ανεξάρτητα τμήματα της λίστας.
\
\
=== 2) Fine-grain locking 
\
Σε αυτήν την υλοποίηση υπάρχει ένα κλείδωμα για κάθε στοιχείο της λίστας. Ο τρόπος διάσχισης είναι hand-over-hand locking δηλαδή ένα νήμα προσπαθεί να δεσμεύσει τον επόμενο, όταν τα καταφέρει, αφήνει τον προηγούμενο. Αυτό είναι αναγκαστικό προς αποφυγή deadlock, εφόσον για ένα operation απαιτούνται κλειδώματα σε 2 στοιχεία (pred, curr) και θα δημιουργούνταν πρόβλημα αν 2 νήματα επιχειρούσαν να αλλάξουν 2 γειτονικά nodes και προσπαθούσαν να πάρουν τα κλειδώματα με αντίθετη σειρά. Μπορεί να δουλέψει καλύτερα από την coarse grain σε συγκεκριμένες περιπτώσεις αλλά το σημαντικότερο πρόβλημα είναι πως αν ένα νήμα θέλει να αλλάξει κάτι που βρίσκεται νωρίς στη λίστα, μπλοκάρει όλα τα άλλα νήματα που θέλουν να ψάξουν ή αλλάξουν κάτι που είναι πιο μετά στη λίστα.
\
\
=== 3) Optimistic synchronization
\
Σε αυτήν την υλοποίηση ένα νήμα για κάθε αλλαγή, βρίσκει τον προηγούμενο και τον επόμενο προς αλλαγή, προσπαθεί να τους δεσμεύσει, ελέγχει αν η δομή είναι ακόμη συνεπής(δηλαδή είναι προσβάσιμοι και διαδοχικοί) και κάνει την αλλαγή. Η contains στη συγκεκριμένη υλοποίηση χρησιμοποιεί επίσης κλειδώματα αν και δεν χρειάζεται. Το κύριο πρόβλημα αυτής της υλοποίησης είναι πως η validate διατρέχει όλη την λίστα για να επιβεβαιώσει την συνέπεια και αυτό είναι πάρα πολύ χρονοβόρο.
\
\
=== 4) Lazy synchronization
Σε αυτήν την υλοποίηση προσθέτουμε στη δομή μια boolean μεταβλητή που δείχνει αν ο κόμβος βρίσκεται στη λίστα ή έχει διαγραφεί. Η contains διατρέχει τη λίστα χωρίς να κλειδώνει και ελέγχει αυτήν την boolean μεταβλητή οπότε είναι wait-free. Η validate δεν διατρέχει την λίστα αλλά κάνει τοπικούς ελέγχους στον προηγούμενο και επόμενο κόμβο, δηλαδή ελέγχει αν ανήκουν στη δομή και οι 2 με την επιπλέον μεταβλητή και ο next του προηγούμενο είναι ο τωρινός. Η add/remove κάνουν πρώτα λογική και μετά φυσική αλλαγή των κόμβων.
\
\
=== 5) Non-blocking
\
Σε αυτήν την υλοποίηση προσπαθούμε να αφαίρουμε τελείως την ανάγκη για κλειδώματα και να χρησιμοποιήσουμε τις ατομικές εντολές που μας δίνει το instruction set του εκάστοτε επεξεργαστή. Η κεντρική ιδέα είναι να χειριστούμε την boolean μεταβλητή marked και το πεδίο next σαν μία μεταβλητή. Κάνει ατομικό σύνθετο έλεγχο και αλλαγή με 1 εντολή compare and set. Έτσι η διαγραφή κάνει με 1 εντολή validate και λογική διαγραφή και 1 μόνο προσπάθεια φυσικής διαγραφή. Η find/contains είναι αυτή που εξετάζει αν υπάρχει στοιχείο που έχει διαγραφεί λογικά και όχι φυσικά και το αναλαμβάνει εκείνη. Η προσθήκη αναγκαστικά ξαναπροσπαθεί μέχρι να τα καταφέρει για να είναι συνεπής η δομή.

\

Μας δίνονται έτοιμες όλες οι παραπάνω ταυτόχρονες υλοποιήσεις. Για την ζητούμενη εκτέλεση, το σειριακό πρόγραμμα εκτελέστηκε μόνο με 1 thread αλλιώς θα υπάρχει πρόβλημα, για 128 νήματα χρησιμοποιήθηκε oversubscription. Δηλαδή η μεταβλητή MT_CONF τέθηκε σε 0,1,...63,0,1,,...63 ώστε να δημιουργηθούν και να πινάρουν 128 νήματα σε συγκεκριμένους πυρήνες. Επειδή οι λογικοί πυρήνες του sandman είναι 64, το scheduling των νημάτων πλέον το αναλαμβάνει το λειτουργικό και το software και όχι το ίδιο το υλικό όπως όταν χρησιμοποιούμε hyperthreading.
\
\
#bash_box("../a2_new/conc_ll/run_on_queue.sh")
#pagebreak()

== Αποτελέσματα
Παρουσιάζονται τα Kops/sec με την μορφή line plots ανά κάθε διαφορετικό workload configuration καθως και το κανονικοποιημένο Kops/sec ανά νήμα με την μορφή barplots για κάθε εκτέλεση με n threads.
\
#align(center)[
\
#image("../a2_new/conc_ll/results/conc_ll_1024_100_0_0.png", width:85%)
#image("../a2_new/conc_ll/results/conc_ll_1024_80_10_10.png",width:85%)
#image("../a2_new/conc_ll/results/conc_ll_1024_20_40_40.png",width:85%)
#image("../a2_new/conc_ll/results/conc_ll_1024_0_50_50.png",width:85%)
\
\
#image("../a2/conc_ll/results/conc_1024_1.png")
#image("../a2/conc_ll/results/conc_1024_2.png")
#image("../a2/conc_ll/results/conc_1024_4.png")
#image("../a2/conc_ll/results/conc_1024_8.png")
#image("../a2/conc_ll/results/conc_1024_16.png")
#image("../a2/conc_ll/results/conc_1024_32.png")
#image("../a2/conc_ll/results/conc_1024_64.png")
#image("../a2/conc_ll/results/conc_1024_128.png")

#pagebreak()

=== Για μήκος λίστας 8192
#image("../a2_new/conc_ll/results/conc_ll_8192_100_0_0.png",width:85%)
#image("../a2_new/conc_ll/results/conc_ll_8192_80_10_10.png",width:85%)
#image("../a2_new/conc_ll/results/conc_ll_8192_20_40_40.png",width:85%)
#image("../a2_new/conc_ll/results/conc_ll_8192_0_50_50.png",width:85%)
\
\
#image("../a2/conc_ll/results/conc_8192_1.png")
#image("../a2/conc_ll/results/conc_8192_2.png")
#image("../a2/conc_ll/results/conc_8192_4.png")
#image("../a2/conc_ll/results/conc_8192_8.png")
#image("../a2/conc_ll/results/conc_8192_16.png")
#image("../a2/conc_ll/results/conc_8192_32.png")
#image("../a2/conc_ll/results/conc_8192_64.png")
#image("../a2/conc_ll/results/conc_8192_128.png")
\
]

#pagebreak()

=== Παρατηρήσεις

H serial εκδοχή μας δείχνει την δυναμική του κάθε core, δεν χρησιμοποιεί παραλληλισμό ούτε κλειδώματα και έχει σταθερό throughput ανεξάρτητα από το πλήθος των νημάτων γι'αυτό και την θεωρούμε ως σημείο αναφοράς.
Tα queries add / delete είναι υπολογιστικά ισοδύναμα οπότε μπορούμε να εξάγουμε το συνολικό ποσοστό τους έναντι των search για την ανάλυσή μας.

\ *Workload 100/0/0* \

Στην περίπτωση που το workload αποτελείται εξ'ολοκλήρου από search queries, oι coarse-grain, fine-grain & και optimistic εκδοχές δεν κλιμακώνουν καθόλου για κανένα μέγεθος λίστας αφού μπλοκάρονται όλες σε κάποιο κλείδωμα (είτε είναι global για όλη την δομή στην πρώτη περίπτωση, είτε στην αρχή της λίστας και περνιέται μέσω hand-over-hand για τις άλλες). ουσιαστικά όλες οι προσβάσεις σειριοποιούνται, οπότε δεν κερδίζουμε τίποτα από τον παραλληλισμό, μονάχα το κόστος δημιουργίας των threads και υλοποίησης των κλειδωμάτων.

Aντίθετα, η lazy είναι wait-free στην αναζήτηση επομένως κερδίζουμε throughput χαριν στον παραλληλισμό χωρίς bottlenecks. Στα 64 - 128 νήματα η επίδοση μένει σταθερή γιατί το μηχάνημα έχει ήδη 100% utilization (64 logical cores).

\ *Workload 80/10/10* \
Προσθέτοντας μικρό ποσοστό add / delete βλέπουμε ότι η επιδόσεις όλων είναι καλύτερες αφού μέρος αυτών των λειτουργιών είναι η συνάρτηση contains που πραγματαποιεί αναζήτηση αλλά με wait free τρόπο. Χειρότερη είναι η fine-grain ειδικότερα αν queries στο τέλος της λίστας έπονται από queries στην αρχή της και αναγκάζονται να μπλοκάρουν μέχρι να αποκτήσουν το lock hand-over-hand τρόπο. Ακόμη, η διαδικασία αυτή εισάγει έξτρα πολυπλοκότητα μέσα από αλλεπάληλες κλήσεις lock / unlock μέχρι να φτάσει στους ζητούμενους κόμβους, οπότε καταλήγει να έχει χειρότερη επίδοση από την coarse-grain. H κατάσταση θα μπορούσε να αλλάξει εαν αντιστρέφαμε την σειρά των queries, όμως αυτά παράγονται τυχαία. 
H optimistic ακολουθεί την λογική readers-writer lock και διατρέχει την λίστα wait free κάνοντας μετά έναν έλεγχο συνέπειας της δομής (validate). Δεν κλιμακώνει όπως θα περίμεναμε επειδή η validate έχει γραμμική πολυπλοκότητα και κυριαρχεί το κόστος να διατρέξει την λίστα από την αρχή. Αντίθετα, η lazy υλοποιεί την validate με σταθερό χρόνο, κοιτάζοντας απλά το valid bit για τους κόμβους pred, curr και από 16 threads και πάνω παρουσιάζει τεράστια κλιμάκωση. 
Τέλος η non-block είναι εγγενώς wait free και αξιοποιεί packed εντολές που παρέχει το ISΑ και είναι optimal.
Η μείωση του throughput από τα 8 στα 16 οφείλεται στο ότι τόσο τα locks όσο και τα list data είναι shared στα threads και βγαίνουμε εκτός NUMA cluster. Δεν ισχύει το ίδιο και για μέγεθος 8192 όπου έτσι και αλλιώς η λίστα δεν χωράει ολόκληρη στην cache.

\ *Workload 20/40/40  & Workload 0/50/50* \
Aυξάνοντας παραπάνω το ποσοστό των add / delete η lazy χάνει σε throughput ενώ η optimistic κερδίζει στην περίπτωση του μικρού size=1024, και δεν παρουσιάζει αισθητές διαφορές για μεγάλο size=8192. Aυτο συμβαίνει επειδή τα conflicts για μεταβολή κοινών δεδομένων είναι σπανιότερα σε μεγάλο μέγεθος λίσταε και εφόσον ο αριθμός των queries μένει σταθερός. Έστι το overhead των locking mechanisms μένει σχετικά σταθερό χάριν στο μικρό contention. Σε κάθε περίπτωση, το throughput στην 2η περίπτωση είναι σημαντικά μικρότερο αφού όλες οι λειτουργίες είναι γραμμικές ως προς το μέγεθος της λίστας και δεν μπορεί να αξιοποιηθεί πλήρως το data locality.






















#pagebreak()

Παρατηρούμε πως :
\
1) Στην περίπτωση που έχουμε μόνο contains την χειρότερη επίδοση την έχει η fine grain που έχει τεράστιο overhead καθώς έχει κλείδωμα για κάθε κόμβο, ενώ η coarse grain που έχει ένα global κλείδωμα τα πάει καλύτερα. 
\
2) Στην ίδια περίπτωση για το μεγάλο μέγεθος λίστας οι coarse grain, fine grain, optimistic έχουν φυσιολογικές επιδόσεις μέχρι 8 νήματα, με το που χρησιμοποιήσουμε παραπάνω από 1 cluster με μη κοινή L3 cache τα πάνε χάλια. Αυτό συμβαίνει διότι διασχίζουν την λίστα πολλές φορές για κάθε αλλαγή και αυτό σε συνδυασμό με το πρωτόκολλο συνάφεια κρυφής μνήμης προκαλεί τεράστιες καθυστερήσεις.
\
3) Η non blocking έχει πιο κακή επίδοση στη μικρή λίστα ενώ στη μεγάλη είναι το ίδιο καλή με την lazy. Αυτό είναι λογικό καθώς η φυσική διαγραφή δεν γίνεται πάντα.
\
4) Η lazy synchronization έχει τις καλύτερες επιδόσεις σχεδόν σε όλες τις περιπτώσεις και φτάνει πολύ κοντά στο ιδανικό όταν έχουμε μόνο contains. Αυτό συμβαίνει διότι διατρέχει μόνο 1 φορά τη λίστα για κάθε πράξη και δεν δεσμεύει περιττά κλειδώματα.
\
5) Δεν υπάρχουν σημαντικές διαφορές ανάμεσα στα υπόλοιπα workloads καθώς η contain είναι πιο wait-free μέθοδος και άμα κάνουν όλοι το ίδιο δεν περιμένουν τόσο.
\
6) Σε όλες τις περιπτώσεις το oversubscription είναι κακή ιδέα καθώς η επίδοση ή μένει ίδια(όταν έχουμε μόνο contains) ή πέφτει αισθητά από τα 64 νήματα. Βλέπουμε πως όταν εμπλακεί το λειτουργικό για το scheduling η επίδοση πέφτει πολύ.
\

#pagebreak()

== Παράρτημα
Για την δημιουργία των γραφικών παραστάσεων χρημιοποίηθηκαν oι εξής κώδικες σε Python :

#my_sourcefile("../a2_new/kmeans/results/scraping_kmeans.py")
\
\
#my_sourcefile("../a2/conc_ll/results/conc_plt.py")

